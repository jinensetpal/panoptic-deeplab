{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encoder-aspp-decoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinensetpal/panoptic-reproducibility/blob/main/encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6hF0emftx4h",
        "outputId": "f1850041-472b-49e8-92d1-ad13b634c447"
      },
      "source": [
        "!curl https://rclone.org/install.sh | sudo bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4491  100  4491    0     0   6941      0 --:--:-- --:--:-- --:--:--  6930\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    15  100    15    0     0     16      0 --:--:-- --:--:-- --:--:--    16\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13.8M  100 13.8M    0     0  7788k      0  0:00:01  0:00:01 --:--:-- 7784k\n",
            "Archive:  rclone-current-linux-amd64.zip\n",
            "   creating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/\n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/README.txt  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/rclone.1  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/README.html  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/git-log.txt  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.55.1-linux-amd64/rclone  [binary]\n",
            "Purging old database entries in /usr/share/man...\n",
            "Processing manual pages under /usr/share/man...\n",
            "Purging old database entries in /usr/share/man/ko...\n",
            "Processing manual pages under /usr/share/man/ko...\n",
            "Purging old database entries in /usr/share/man/zh_TW...\n",
            "Processing manual pages under /usr/share/man/zh_TW...\n",
            "Purging old database entries in /usr/share/man/ru...\n",
            "Processing manual pages under /usr/share/man/ru...\n",
            "Purging old database entries in /usr/share/man/fr...\n",
            "Processing manual pages under /usr/share/man/fr...\n",
            "Purging old database entries in /usr/share/man/ja...\n",
            "Processing manual pages under /usr/share/man/ja...\n",
            "Purging old database entries in /usr/share/man/sv...\n",
            "Processing manual pages under /usr/share/man/sv...\n",
            "Purging old database entries in /usr/share/man/tr...\n",
            "Processing manual pages under /usr/share/man/tr...\n",
            "Purging old database entries in /usr/share/man/es...\n",
            "Processing manual pages under /usr/share/man/es...\n",
            "Purging old database entries in /usr/share/man/pl...\n",
            "Processing manual pages under /usr/share/man/pl...\n",
            "Purging old database entries in /usr/share/man/nl...\n",
            "Processing manual pages under /usr/share/man/nl...\n",
            "Purging old database entries in /usr/share/man/id...\n",
            "Processing manual pages under /usr/share/man/id...\n",
            "Purging old database entries in /usr/share/man/cs...\n",
            "Processing manual pages under /usr/share/man/cs...\n",
            "Purging old database entries in /usr/share/man/hu...\n",
            "Processing manual pages under /usr/share/man/hu...\n",
            "Purging old database entries in /usr/share/man/fi...\n",
            "Processing manual pages under /usr/share/man/fi...\n",
            "Purging old database entries in /usr/share/man/zh_CN...\n",
            "Processing manual pages under /usr/share/man/zh_CN...\n",
            "Purging old database entries in /usr/share/man/da...\n",
            "Processing manual pages under /usr/share/man/da...\n",
            "Purging old database entries in /usr/share/man/it...\n",
            "Processing manual pages under /usr/share/man/it...\n",
            "Purging old database entries in /usr/share/man/de...\n",
            "Processing manual pages under /usr/share/man/de...\n",
            "Purging old database entries in /usr/share/man/pt...\n",
            "Processing manual pages under /usr/share/man/pt...\n",
            "Purging old database entries in /usr/share/man/pt_BR...\n",
            "Processing manual pages under /usr/share/man/pt_BR...\n",
            "Purging old database entries in /usr/share/man/sr...\n",
            "Processing manual pages under /usr/share/man/sr...\n",
            "Processing manual pages under /usr/local/man...\n",
            "Updating index cache for path `/usr/local/man/man1'. Wait...done.\n",
            "Checking for stray cats under /usr/local/man...\n",
            "Checking for stray cats under /var/cache/man/oldlocal...\n",
            "1 man subdirectory contained newer manual pages.\n",
            "4 manual pages were added.\n",
            "0 stray cats were added.\n",
            "19 old database entries were purged.\n",
            "\n",
            "rclone v1.55.1 has successfully installed.\n",
            "Now run \"rclone config\" for setup. Check https://rclone.org/docs/ for more details.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT8fQZ3SlDvL",
        "outputId": "ae8cdb57-2efd-4459-8b9b-9d7dd9f53cea"
      },
      "source": [
        "# !rclone config ; cp /root/.config/rclone/rclone.conf .\n",
        "!wget https://66931f1295a8.ngrok.io/rclone.conf ; mkdir -p /root/.config/rclone/ ; cp rclone.conf /root/.config/rclone/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-27 06:36:47--  https://66931f1295a8.ngrok.io/rclone.conf\n",
            "Resolving 66931f1295a8.ngrok.io (66931f1295a8.ngrok.io)... 3.134.125.175, 2600:1f16:d83:1200::6e:3\n",
            "Connecting to 66931f1295a8.ngrok.io (66931f1295a8.ngrok.io)|3.134.125.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3686 (3.6K) [text/plain]\n",
            "Saving to: ‘rclone.conf’\n",
            "\n",
            "rclone.conf         100%[===================>]   3.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-27 06:36:47 (59.1 MB/s) - ‘rclone.conf’ saved [3686/3686]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580BmQpJQS_x"
      },
      "source": [
        "!sudo mkdir /content/onedrive\n",
        "!nohup rclone --vfs-cache-mode writes mount colab: /content/onedrive &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PwZ8vQRm9Ce"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications.xception import Xception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTIzeC8Tm-xg",
        "outputId": "0f282a0b-d8c0-4c1f-c3b5-149d1eec9c85"
      },
      "source": [
        "encoder = Xception(input_shape=(1029, 2049, 3),\n",
        "                      include_top=False,\n",
        "                      weights='imagenet')\n",
        "\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1029, 2049,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 514, 1024, 32 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 514, 1024, 32 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 514, 1024, 32 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 512, 1022, 64 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 512, 1022, 64 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 512, 1022, 64 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 512, 1022, 12 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 512, 1022, 12 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 512, 1022, 12 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 512, 1022, 12 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 512, 1022, 12 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 511, 128 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 256, 511, 128 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 511, 128 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256, 511, 128 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 256, 511, 128 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 256, 511, 256 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 256, 511, 256 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 256, 511, 256 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 256, 511, 256 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 256, 511, 256 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 256, 256 32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 128, 256, 256 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 256, 256 1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128, 256, 256 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 128, 256, 256 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 128, 256, 728 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 128, 256, 728 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 128, 256, 728 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 128, 256, 728 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 128, 256, 728 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 128, 728) 186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 64, 128, 728) 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 128, 728) 2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 128, 728) 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 64, 128, 728) 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 64, 128, 728) 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 64, 128, 728) 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 64, 128, 728) 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 64, 128, 728) 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 64, 128, 728) 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 64, 128, 728) 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 64, 128, 728) 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 64, 128, 728) 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 128, 728) 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 64, 128, 728) 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 64, 128, 728) 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 64, 128, 728) 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 64, 128, 728) 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 64, 128, 728) 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 64, 128, 728) 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 64, 128, 728) 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 64, 128, 728) 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 64, 128, 728) 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 64, 128, 728) 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 64, 128, 728) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 64, 128, 728) 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 64, 128, 728) 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 64, 128, 728) 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 64, 128, 728) 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 64, 128, 728) 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 64, 128, 728) 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 64, 128, 728) 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 64, 128, 728) 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 64, 128, 728) 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 64, 128, 728) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 64, 128, 728) 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 64, 128, 728) 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 64, 128, 728) 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 64, 128, 728) 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 64, 128, 728) 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 64, 128, 728) 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 64, 128, 728) 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 64, 128, 728) 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 64, 128, 728) 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 64, 128, 728) 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 64, 128, 728) 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 64, 128, 728) 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 64, 128, 728) 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 64, 128, 728) 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 64, 128, 728) 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 64, 128, 728) 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 64, 128, 728) 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 64, 128, 728) 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 128, 728) 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 64, 128, 728) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 64, 128, 728) 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 64, 128, 728) 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 64, 128, 728) 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 64, 128, 728) 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 64, 128, 728) 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 64, 128, 728) 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 64, 128, 728) 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 64, 128, 728) 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 128, 728) 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 64, 128, 728) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 64, 128, 728) 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 64, 128, 728) 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 64, 128, 728) 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 64, 128, 728) 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 64, 128, 728) 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 64, 128, 728) 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 64, 128, 728) 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 64, 128, 728) 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 128, 728) 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 64, 128, 728) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 64, 128, 728) 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 64, 128, 728) 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 64, 128, 728) 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 64, 128, 728) 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 64, 128, 728) 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 64, 128, 728) 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 64, 128, 728) 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 64, 128, 728) 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 64, 128, 728) 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 64, 128, 728) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 64, 128, 728) 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 64, 128, 728) 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 64, 128, 728) 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 64, 128, 1024 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 64, 128, 1024 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 64, 1024) 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 32, 64, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 64, 1024) 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 64, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 32, 64, 1536) 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 32, 64, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 32, 64, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 32, 64, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 32, 64, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 32, 64, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lob7iVBufYs6",
        "outputId": "5aefb7f1-705c-4578-87c7-2eb92c09fd92"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYE6d-zLeDSE"
      },
      "source": [
        "conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.2)(conv3)\n",
        "conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.2)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xow35yIyfwFz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications.Xception import Xception\n",
        "\n",
        "latent_dim = 64\n",
        "class EncoderDecoder(Xception):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder(latent_dim)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Yi2oOeEf5N"
      },
      "source": [
        "!pip install keras_segmentation tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUw5P8fbd7Q3"
      },
      "source": [
        "import tf_slim as slim\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def atrous_spatial_pyramid_pooling(net, scope, depth=256):\n",
        "  with tf.variable_scope(scope):\n",
        "    feature_map_size = tf.shape(net)\n",
        "\n",
        "    # apply global average pooling\n",
        "    image_level_features = tf.reduce_mean(net, [1, 2], name='image_level_global_pool', keep_dims=True)\n",
        "    image_level_features = slim.conv2d(image_level_features, depth, [1, 1], scope=\"image_level_conv_1x1\", activation_fn=None)\n",
        "    image_level_features = tf.image.resize_bilinear(image_level_features, (feature_map_size[1], feature_map_size[2]))\n",
        "\n",
        "    at_pool1x1 = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_0\", activation_fn=None)\n",
        "\n",
        "    at_pool3x3_1 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_1\", rate=6, activation_fn=None)\n",
        "\n",
        "    at_pool3x3_2 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_2\", rate=12, activation_fn=None)\n",
        "\n",
        "    at_pool3x3_3 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_3\", rate=18, activation_fn=None)\n",
        "\n",
        "    net = tf.concat((image_level_features, at_pool1x1, at_pool3x3_1, at_pool3x3_2, at_pool3x3_3), axis=3, name=\"concat\")\n",
        "    net = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_output\", activation_fn=None)\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG_gAbwvPx0t"
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "\n",
        "def deeplab_v3(inputs, args, is_training, reuse):\n",
        "\n",
        "    # mean subtraction normalization\n",
        "    inputs = inputs - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
        "\n",
        "    # inputs has shape [batch, 513, 513, 3]\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope(args.l2_regularizer, is_training,\n",
        "                                                      args.batch_norm_decay,\n",
        "                                                      args.batch_norm_epsilon)):\n",
        "        xception = Xception(input_shape=(1029, 2049, 3),\n",
        "                          include_top=False,\n",
        "                          weights='imagenet')\n",
        "        _, end_points = xception(inputs,\n",
        "                                 args.number_of_classes,\n",
        "                                 is_training=is_training,\n",
        "                                 global_pool=True,\n",
        "                                 spatial_squeeze=False,\n",
        "                                 output_stride=args.output_stride,\n",
        "                                 reuse=reuse)\n",
        "\n",
        "        with tf.variable_scope(\"DeepLab_v3\", reuse=reuse):\n",
        "\n",
        "            # get block 4 feature outputs\n",
        "            net = end_points[args.resnet_model + '/block4']\n",
        "            net = atrous_spatial_pyramid_pooling(net, \"ASPP_layer\", depth=256, reuse=reuse)\n",
        "            net = slim.conv2d(net, args.number_of_classes, [1, 1], activation_fn=None,\n",
        "                              normalizer_fn=None, scope='logits')\n",
        "\n",
        "            size = tf.shape(inputs)[1:3]\n",
        "            net = tf.image.resize_bilinear(net, size)\n",
        "            return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nXDNO6RVQXHO",
        "outputId": "653e45b2-7681-4577-9936-e225b85d532d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import Model\n",
        "from keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Add\n",
        "from keras_segmentation.models.model_utils import get_segmentation_model\n",
        "\n",
        "# encoder-decoder\n",
        "def buildmodel(input_img, n_classes=17, TRAINABLE=False):\n",
        "\n",
        "    base_model = Xception(input_shape=(1029, 2049, 3),\n",
        "                          include_top=False,\n",
        "                          weights='imagenet')\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable=TRAINABLE\n",
        "    \n",
        "#-------------------encoder---------------------------- \n",
        "#--------(pretrained & trainable if selected)----------\n",
        "\n",
        "    x=base_model.get_layer('block1_conv1')(input_img)\n",
        "    x=base_model.get_layer('block1_conv1_bn')(x)\n",
        "    x=base_model.get_layer('block1_conv1_act')(x)\n",
        "    x=base_model.get_layer('block1_conv2')(x)\n",
        "    x=base_model.get_layer('block1_conv2_bn')(x)\n",
        "    x=base_model.get_layer('block1_conv2_act')(x)\n",
        "\n",
        "#    block1 -- 1/4\n",
        "    x=base_model.get_layer('block2_sepconv1')(x)\n",
        "    # x=base_model.get_layer('block2_sepconv1')(input_img)\n",
        "    x=base_model.get_layer('block2_sepconv1_bn')(x)\n",
        "    x=base_model.get_layer('block2_sepconv2_act')(x)\n",
        "    x=base_model.get_layer('block2_sepconv2')(x)\n",
        "    x=base_model.get_layer('block2_sepconv2_bn')(x)\n",
        "    x=base_model.get_layer('conv2d')(x)\n",
        "    # x=Conv2D(256, (1, 1), activation=None, padding='same')(x)\n",
        "    x=base_model.get_layer('block2_pool')(x)\n",
        "    x=base_model.get_layer('batch_normalization')(x)\n",
        "    # x=BatchNormalization(axis=-1)(x)\n",
        "    ups1=base_model.get_layer('add')(x)\n",
        "\n",
        "#    block2 -- 1/8\n",
        "    x=base_model.get_layer('block3_sepconv1_act')(ups1)\n",
        "    x=base_model.get_layer('block3_sepconv1')(x)\n",
        "    x=base_model.get_layer('block3_sepconv1_bn')(x)\n",
        "    x=base_model.get_layer('block3_sepconv2_act')(x)\n",
        "    x=base_model.get_layer('block3_sepconv2')(x)\n",
        "    x=base_model.get_layer('block3_sepconv2_bn')(x)\n",
        "    x=base_model.get_layer('conv2d_1')(x)\n",
        "    x=base_model.get_layer('block3_pool')(x)\n",
        "    x=base_model.get_layer('batch_normalization_1')(x)\n",
        "    ups2=base_model.get_layer('add_1')(x)\n",
        "\n",
        "#    block3 -- 1/16\n",
        "    x=base_model.get_layer('block4_sepconv1_act')(ups2)\n",
        "    x=base_model.get_layer('block4_sepconv1')(x)\n",
        "    x=base_model.get_layer('block4_sepconv1_bn')(x)    \n",
        "    x=base_model.get_layer('block4_sepconv2_act')(x)\n",
        "    x=base_model.get_layer('block4_sepconv2')(x)\n",
        "    x=base_model.get_layer('block4_sepconv2_bn')(x)\n",
        "    x=base_model.get_layer('conv2d_2')(x)\n",
        "    x=base_model.get_layer('block4_pool')(x)\n",
        "    x=base_model.get_layer('batch_normalization_2')(x)\n",
        "    x=base_model.get_layer('add_2')(x)\n",
        "\n",
        "#    block4 -- 1/16\n",
        "    x=base_model.get_layer('block5_sepconv1_act')(x)\n",
        "    x=base_model.get_layer('block5_sepconv1')(x)\n",
        "    x=base_model.get_layer('block5_sepconv1_bn')(x)    \n",
        "    x=base_model.get_layer('block5_sepconv2_act')(x)\n",
        "    x=base_model.get_layer('block5_sepconv2')(x)\n",
        "    x=base_model.get_layer('block5_sepconv2_bn')(x)\n",
        "    x=base_model.get_layer('block5_sepconv3_act')(x)\n",
        "    x=base_model.get_layer('block5_sepconv3')(x)\n",
        "    x=base_model.get_layer('block5_sepconv3_bn')(x)\n",
        "    x=base_model.get_layer('add_3')(x)\n",
        "    \n",
        "#--------latent space (trainable) ------------\n",
        "    x = atrous_spatial_pyramid_pooling(x, scope=\"aspp\")\n",
        "#--------------decoder (trainable)----------- \n",
        "    # Block 5    \n",
        "    x = Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "\n",
        "    # Block 6 \n",
        "    x = Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
        "    x = concatenate([UpSampling2D((2, 2))(x), ups1], axis=-1)\n",
        "\n",
        "    # Block 7\n",
        "    x = Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "    x = concatenate([UpSampling2D((2, 2))(x), ups2], axis=-1)\n",
        "\n",
        "    # Block 8\n",
        "    x = Conv2D(256, (5, 5), activation='relu', padding='same')(x)\n",
        "\n",
        "    # Block 9 \n",
        "    x = Conv2D(256, (5, 5), activation='relu', padding='same')(x)\n",
        "\n",
        "    # Block 10 \n",
        "    x = Conv2D(n_classes, (5, 5), activation='relu', padding='same')(x)\n",
        "    \n",
        "    return get_segmentation_model(input_img, x) \n",
        "\n",
        "input_image = Input(shape = (1029, 2049, 3))\n",
        "\n",
        "seg = buildmodel(input_image)\n",
        "seg.compile(loss='mean_squared_error', optimizer = Adam())\n",
        "seg.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1_bn/gamma:0' shape=(32,) dtype=float32>\n",
            "  <tf.Variable 'block1_conv1_bn/beta:0' shape=(32,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 32, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2_bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'block1_conv2_bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_sepconv1/depthwise_kernel:0' shape=(3, 3, 64, 1) dtype=float32>\n",
            "  <tf.Variable 'block2_sepconv1/pointwise_kernel:0' shape=(1, 1, 64, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_sepconv1_bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'block2_sepconv1_bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_sepconv2/depthwise_kernel:0' shape=(3, 3, 128, 1) dtype=float32>\n",
            "  <tf.Variable 'block2_sepconv2/pointwise_kernel:0' shape=(1, 1, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_sepconv2_bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'block2_sepconv2_bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-45060b131eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1029\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2049\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-45060b131eab>\u001b[0m in \u001b[0;36mbuildmodel\u001b[0;34m(input_img, n_classes, TRAINABLE)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block2_sepconv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block2_sepconv2_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# x=Conv2D(256, (1, 1), activation=None, padding='same')(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block2_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d."
          ]
        }
      ]
    }
  ]
}