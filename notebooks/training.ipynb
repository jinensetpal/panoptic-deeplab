{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(os.getcwd()).resolve().parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jinen/git/panoptic-reproducibility\n"
     ]
    }
   ],
   "source": [
    "%cd $BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.const.load_data_const import SEED_TRAIN, SEED_VAL, SEED_TEST\n",
    "from src.const.general_const import BASE_DATA_PATH, IMG_SIZE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from src.data_generator import DataGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "j0L1FyyiQwYx"
   },
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = os.path.join(BASE_DIR, 'data', 'example', 'cityscapes')\n",
    "partition = {}\n",
    "partition = {'train': glob.glob(os.path.join(BASE_DATA_PATH, 'gtFine', 'train', '*', '*color*')),\n",
    "             'val': glob.glob(os.path.join(BASE_DATA_PATH, 'gtFine', 'val', '*', '*color*')),\n",
    "             'test': glob.glob(os.path.join(BASE_DATA_PATH, 'gtFine', 'test', '*', '*color*'))} \n",
    "\n",
    "params = {'dim': IMG_SIZE,\n",
    "          'batch_size': 2,\n",
    "          'n_classes': 19,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'augment': {'zoom_range': [5, 20],\n",
    "                      'random_flip': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jinen/git/panoptic-reproducibility/data/example/cityscapes/gtFine/train/bochum/bochum_000000_000313_gtFine_color.png',\n",
       " '/home/jinen/git/panoptic-reproducibility/data/example/cityscapes/gtFine/train/bochum/bochum_000000_000600_gtFine_color.png',\n",
       " '/home/jinen/git/panoptic-reproducibility/data/example/cityscapes/gtFine/train/aachen/aachen_000000_000019_gtFine_color.png',\n",
       " '/home/jinen/git/panoptic-reproducibility/data/example/cityscapes/gtFine/train/aachen/aachen_000001_000019_gtFine_color.png']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IsG3oCjR1XH5"
   },
   "outputs": [],
   "source": [
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], state='train', seed=SEED_TRAIN, **params)\n",
    "validation_generator = DataGenerator(partition['val'], state='val', seed=SEED_VAL, **params)\n",
    "test_generator = DataGenerator(partition['test'], state='test', seed=SEED_TEST, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx_TKSCBIcui"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S9XLlJ4mLtdN"
   },
   "outputs": [],
   "source": [
    "from src.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DayZZVmgLqkB",
    "outputId": "9c633ca3-bc63-4750-9151-e188eeee2c34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.build_model' from '/home/jinen/git/panoptic-reproducibility/src/models/build_model.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4NA_aYDwB5PW",
    "outputId": "072dbe97-1677-4331-e174-78dcffe299fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 11:28:40.766087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:40.868067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:40.868250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:40.869166: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-25 11:28:40.870004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:40.870137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:40.870245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:41.547153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:41.547326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:41.547431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 11:28:41.547820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1436 MB memory:  -> device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RES2: (None, 255, 511, 128)\n",
      "RES3: (None, 128, 256, 256)\n",
      "TENSORTYPE\n",
      "TENSORTYPE\n",
      "<class 'dict'>\n",
      "{'res5': <KerasTensor: shape=(None, 64, 128, 728) dtype=float32 (created by layer 'model')>, 'res2': <KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>, 'res3': <KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>}\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 255, 511, 128), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\") KerasTensor(type_spec=TensorSpec(shape=(None, 128, 256, 256), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "True\n",
      "run with this\n",
      "{'res5': <tf.Tensor 'Placeholder_2:0' shape=(None, 64, 128, 728) dtype=float32>, 'res2': <tf.Tensor 'Placeholder:0' shape=(None, 255, 511, 128) dtype=float32>, 'res3': <tf.Tensor 'Placeholder_1:0' shape=(None, 128, 256, 256) dtype=float32>}\n",
      "{'res2': <KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>, 'res3': <KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>}\n",
      "{'res5': <tf.Tensor 'Placeholder_2:0' shape=(None, 64, 128, 728) dtype=float32>, 'res2': <KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>, 'res3': <KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>}\n",
      "['res5']\n",
      "{'res5': <tf.Tensor 'Placeholder_2:0' shape=(None, 64, 128, 728) dtype=float32>, 'res2': <KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>, 'res3': <KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>}\n",
      "<class 'dict'>\n",
      "ListWrapper(['res3', 'res2'])\n",
      "IMP: ['res3']\n",
      "TYPE: <class 'list'>\n",
      "FEATURES COMPARISON\n",
      "target_h KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.int32, name=None), inferred_value=[128], name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n",
      "target_w KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.int32, name=None), inferred_value=[256], name='tf.__operators__.getitem_1/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_1'\")\n",
      "source_h Tensor(\"semantic_decoder/strided_slice:0\", shape=(), dtype=int32)\n",
      "source_w Tensor(\"semantic_decoder/strided_slice_1:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"semantic_decoder\" (type PanopticDeepLabSingleDecoder).\n\nin user code:\n\n    File \"/home/jinen/git/panoptic-reproducibility/src/models/decoder.py\", line 161, in call  *\n        tf.assert_less(\n    File \"/home/jinen/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py\", line 107, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"/home/jinen/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Could not build a TypeSpec for name: \"tf.debugging.assert_less/assert_less/Assert/Assert\"\n    op: \"Assert\"\n    input: \"tf.debugging.assert_less/assert_less/All\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_0\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_1\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_2\"\n    input: \"tf.debugging.assert_less/assert_less/Less/semantic_decoder/sub\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_4\"\n    input: \"strided_slice\"\n    attr {\n      key: \"T\"\n      value {\n        list {\n          type: DT_STRING\n          type: DT_STRING\n          type: DT_STRING\n          type: DT_INT32\n          type: DT_STRING\n          type: DT_INT32\n        }\n      }\n    }\n    attr {\n      key: \"summarize\"\n      value {\n        i: 3\n      }\n    }\n     of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.\n\n\nCall arguments received:\n  • features={'res5': 'tf.Tensor(shape=(None, 64, 128, 728), dtype=float32)', 'res2': \"<KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>\", 'res3': \"<KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>\"}\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m      6\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/git/panoptic-reproducibility/src/models/build_model.py:44\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     41\u001b[0m inst_decoder\u001b[38;5;241m.\u001b[39m_skip \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres2\u001b[39m\u001b[38;5;124m'\u001b[39m: res2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres3\u001b[39m\u001b[38;5;124m'\u001b[39m: res3}\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#sem_decoder.put_skip(res2, res3)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#inst_decoder.put_skip(res2, res3)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m sem_latent, inst_latent \u001b[38;5;241m=\u001b[39m \u001b[43msem_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[43m)\u001b[49m, inst_decoder(latent)\n\u001b[1;32m     45\u001b[0m sem_output, inst_ctr_output, inst_rgr_output \u001b[38;5;241m=\u001b[39m sem_head(sem_latent), inst_ctr_head(inst_latent), inst_rgr_head(inst_latent)\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minp, outputs\u001b[38;5;241m=\u001b[39m[sem_output, inst_ctr_output, inst_rgr_output])\n",
      "File \u001b[0;32m~/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"semantic_decoder\" (type PanopticDeepLabSingleDecoder).\n\nin user code:\n\n    File \"/home/jinen/git/panoptic-reproducibility/src/models/decoder.py\", line 161, in call  *\n        tf.assert_less(\n    File \"/home/jinen/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py\", line 107, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"/home/jinen/git/panoptic-reproducibility/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Could not build a TypeSpec for name: \"tf.debugging.assert_less/assert_less/Assert/Assert\"\n    op: \"Assert\"\n    input: \"tf.debugging.assert_less/assert_less/All\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_0\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_1\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_2\"\n    input: \"tf.debugging.assert_less/assert_less/Less/semantic_decoder/sub\"\n    input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_4\"\n    input: \"strided_slice\"\n    attr {\n      key: \"T\"\n      value {\n        list {\n          type: DT_STRING\n          type: DT_STRING\n          type: DT_STRING\n          type: DT_INT32\n          type: DT_STRING\n          type: DT_INT32\n        }\n      }\n    }\n    attr {\n      key: \"summarize\"\n      value {\n        i: 3\n      }\n    }\n     of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.\n\n\nCall arguments received:\n  • features={'res5': 'tf.Tensor(shape=(None, 64, 128, 728), dtype=float32)', 'res2': \"<KerasTensor: shape=(None, 255, 511, 128) dtype=float32 (created by layer 'add')>\", 'res3': \"<KerasTensor: shape=(None, 128, 256, 256) dtype=float32 (created by layer 'add_1')>\"}\n  • training=False"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from src.models import build_model\n",
    "\n",
    "model = build_model.get_model()\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "collapsed": true,
    "id": "VaTn0oVh1JWs",
    "outputId": "c26adc05-34e5-401e-f23f-c2fa14674e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS -\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ab9ea5cd3870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INPUTS -\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OUTPUTS -\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LAYERS -\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"INPUTS -\")\n",
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "print(\"OUTPUTS -\")\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "print(\"LAYERS -\")\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOh9YUklmzVJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from src.models.loss import loss_panoptic\n",
    "from src.models.metrics import get_metrics\n",
    "from src import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQ4IEOZbchd-"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "collapsed": true,
    "id": "d7ksbReAXlRC",
    "outputId": "625889db-d2b4-4984-fa3f-77bcc9863475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running once\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c32d941ab68b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running once'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_panoptic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/panoptic-reproducibility/src/models/loss.py\u001b[0m in \u001b[0;36mloss_panoptic\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlam_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msemantic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGT_KEY_SEMANTIC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRED_KEY_SEMANTIC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     instance_center_loss = loss_instance_center(y_true[common.GT_KEY_INSTANCE_CENTER],\n\u001b[1;32m     24\u001b[0m                                                 y_pred[common.PRED_KEY_INSTANCE_CENTER])\n",
      "\u001b[0;32m/content/panoptic-reproducibility/src/models/loss.py\u001b[0m in \u001b[0;36mloss_sem\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_sem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m                                  lambda: y_true)\n\u001b[1;32m   1643\u001b[0m   return backend.categorical_crossentropy(\n\u001b[0;32m-> 1644\u001b[0;31m       y_true, y_pred, from_logits=from_logits)\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4860\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4861\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4862\u001b[0;31m   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4864\u001b[0m   \u001b[0;31m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \"\"\"\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1025, 2049, 4) and (2, 64, 128, 19) are incompatible"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "  for batch in range(training_generator.__len__()):\n",
    "    X, y = training_generator.__getitem__(batch)\n",
    "    with tf.GradientTape() as tape:\n",
    "      seg_pred, kpt_pred, regr_pred = model(X, training=True)\n",
    "      y_pred = {}\n",
    "      y_pred.update(seg_pred)\n",
    "      y_pred.update(kpt_pred)\n",
    "      y_pred.update(regr_pred)\n",
    "      \n",
    "      loss = loss_panoptic(y[batch], y_pred)\n",
    "      gradients = tape.gradient(loss, tape.watched_variables())\n",
    "      optimizer.apply_gradients(zip(gradients, tape.watched_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_z604f1zufl"
   },
   "source": [
    "# Commit Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvym9JU-cytP"
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCRtuk5Rzt4r"
   },
   "outputs": [],
   "source": [
    "# !dvc add\n",
    "\n",
    "# !git add\n",
    "\n",
    "# !git commit\n",
    "\n",
    "# !git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CjjbKpyz4u5"
   },
   "source": [
    "# Push Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Loqm2x1Grhrj"
   },
   "outputs": [],
   "source": [
    "# !git push https://{GITHUB_USER_NAME}:{GITHUB_TOKEN}@github.com/{GITHUB_REPO_OWNER}/{GITHUB_REPO_NAME}.git {BRANCH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Fsal7eKxzt9"
   },
   "outputs": [],
   "source": [
    "# !dvc push -r origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9qx1MaKljEx"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "panoptic-reproducibility",
   "language": "python",
   "name": "panoptic-reproducibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
